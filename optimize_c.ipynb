{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quake.utils.utils import load_runcard\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from src.quake.models.svm.utils import extract_feats, rearrange_scale\n",
    "from src.quake.models.attention.train import load_and_compile_network as load_attention_network\n",
    "from src.quake.models.attention.attention_dataloading import read_data as read_data_attention\n",
    "from src.quake.models.cnn.cnn_dataloading import read_data as read_data_cnn\n",
    "from src.quake.models.cnn.train import load_and_compile_network as load_cnn_network\n",
    "from quake.dataset.generate_utils import Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_folder: Path, train_folder: Path, extractor_type: str, setup: dict, seed: int = 42, run_tf_eagerly: bool = False):\n",
    "    \"\"\"SVM training.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_folder: Path\n",
    "        The input data folder path.\n",
    "    setup: dict\n",
    "        Settings dictionary.\n",
    "\n",
    "    Raises  \n",
    "    ------\n",
    "    NotImplementedError\n",
    "        If extractor type not one of `svm` or `attention`\n",
    "    \"\"\"\n",
    "    setup.update({\"seed\": seed, \"run_tf_eagerly\": run_tf_eagerly})\n",
    "\n",
    "    load_map_folder = train_folder.parent / extractor_type\n",
    "\n",
    "    if extractor_type == \"cnn\":\n",
    "        read_data_fn = read_data_cnn\n",
    "        load_net_fn = load_cnn_network\n",
    "    elif extractor_type == \"attention\":\n",
    "        read_data_fn = read_data_attention\n",
    "        load_net_fn = load_attention_network\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"exctractor model not implemented, found: {extractor_type}\"\n",
    "        )\n",
    "\n",
    "    train_generator, val_generator, test_generator = read_data_fn(\n",
    "        data_folder, load_map_folder, setup, split_from_maps=True\n",
    "    )\n",
    "\n",
    "    geo = Geometry(setup[\"detector\"])\n",
    "    # extractor setup\n",
    "    esetup = setup[\"model\"][extractor_type]\n",
    "    esetup.update({\"ckpt\": load_map_folder / f\"{extractor_type}.h5\"})\n",
    "    network = load_net_fn(esetup, setup[\"run_tf_eagerly\"], geo=geo)\n",
    "    should_add_extra_feats = setup[\"model\"][\"svm\"][\"should_add_extra_feats\"]\n",
    "    train_features, train_labels = extract_feats(\n",
    "        train_generator, network, should_add_extra_feats\n",
    "    )\n",
    "    val_features, val_labels = extract_feats(\n",
    "        val_generator, network, should_add_extra_feats\n",
    "    )\n",
    "    test_features, test_labels = extract_feats(\n",
    "        test_generator, network, should_add_extra_feats\n",
    "    )\n",
    "\n",
    "    # training and saving the SVMs\n",
    "    dataset = rearrange_scale(\n",
    "        train_features,\n",
    "        val_features,\n",
    "        test_features,\n",
    "        setup[\"model\"][\"svm\"][\"should_do_scaling\"],\n",
    "    )\n",
    "    labels = [train_labels, val_labels, test_labels]\n",
    "\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (quake.cnn) Loading splitting maps from folder: ../output/tmp/models/cnn\n",
      "INFO:quake.cnn:Loading splitting maps from folder: ../output/tmp/models/cnn\n",
      "[INFO] (quake.cnn) Train dataset balancing: 14678 training points, of which 47.53% positives\n",
      "INFO:quake.cnn:Train dataset balancing: 14678 training points, of which 47.53% positives\n",
      "[INFO] (quake.cnn) Validation dataset balancing: 3145 training points, of which 47.82% positives\n",
      "INFO:quake.cnn:Validation dataset balancing: 3145 training points, of which 47.82% positives\n",
      "[INFO] (quake.cnn) Test dataset balancing: 3146 training points, of which 48.16% positives\n",
      "INFO:quake.cnn:Test dataset balancing: 3146 training points, of which 48.16% positives\n",
      "[INFO] (quake.cnn) Loading weights at ../output/tmp/models/cnn/cnn.h5\n",
      "INFO:quake.cnn:Loading weights at ../output/tmp/models/cnn/cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 3s 22ms/step\n",
      "27/27 [==============================] - 1s 26ms/step\n",
      "27/27 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path('../output/tmp/data')\n",
    "train_folder = Path('../output/tmp/models/svm')\n",
    "setup = load_runcard(\"../output/tmp/cards/runcard.yaml\")\n",
    "dataset, labels = get_features(data_folder, train_folder, 'cnn', setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info import Statevector\n",
    "import qutip\n",
    "\n",
    "def get_spherical_coordinates(statevector, qbit):\n",
    "    if qbit == 1:\n",
    "        s0 = statevector[0] + statevector[2]\n",
    "        s1 = statevector[1] + statevector[3]\n",
    "    if qbit == 2:\n",
    "        s0 = statevector[0] + statevector[1]\n",
    "        s1 = statevector[2] + statevector[3]        \n",
    "    r0 = np.abs(s0)\n",
    "    phi0 = np.angle(s0)\n",
    "    r1 = np.abs(s1)\n",
    "    phi1 = np.angle(s1)\n",
    "\n",
    "    r = np.sqrt(r0 ** 2 + r1 ** 2)\n",
    "    theta = 2 * np.arccos(r0/r)\n",
    "    phi = phi1 - phi0\n",
    "    return [theta, phi]\n",
    "\n",
    "def Plot_Bloch(x, featuremap, train_set, train_labels):\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(5)\n",
    "\n",
    "    b1 = qutip.Bloch(fig=fig, axes=ax1)\n",
    "    b1.point_size = [1]\n",
    "    b1.point_marker = ['o']\n",
    "    b2 = qutip.Bloch(fig=fig, axes=ax2)\n",
    "    b2.point_size = [1]\n",
    "    b2.point_marker = ['o']\n",
    "    pnts1 = np.zeros((len(train_labels),3))\n",
    "    pnts2 = np.zeros((len(train_labels),3))\n",
    "    for i, val in enumerate(train_set):\n",
    "        bound_circuits = (featuremap.assign_parameters({x: val}))\n",
    "        state = (Statevector.from_instruction(bound_circuits))\n",
    "        spherical1 = get_spherical_coordinates(state, 1)\n",
    "        x1 = np.sin(spherical1[0])*np.cos(spherical1[1])\n",
    "        y1 = np.sin(spherical1[0])*np.sin(spherical1[1])\n",
    "        z1 = np.cos(spherical1[0])\n",
    "        spherical2 = get_spherical_coordinates(state, 2)\n",
    "        x2 = np.sin(spherical2[0])*np.cos(spherical2[1])\n",
    "        y2 = np.sin(spherical2[0])*np.sin(spherical2[1])\n",
    "        z2 = np.cos(spherical2[0])\n",
    "        pnts1[i] = [x1, y1, z1]\n",
    "        pnts2[i] = [x2, y2, z2]\n",
    "    b1.add_points(pnts1[train_labels == 1].T)\n",
    "    b1.add_points(pnts1[train_labels == 0].T)\n",
    "    b2.add_points(pnts2[train_labels == 1].T)\n",
    "    b2.add_points(pnts2[train_labels == 0].T)\n",
    "    b1.render()\n",
    "    b2.render()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import ParameterVector, QuantumCircuit\n",
    "from qiskit import Aer\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "\n",
    "\n",
    "qubits = dataset[-1].shape[-1]\n",
    "x = ParameterVector('x', length=qubits)\n",
    "backend = Aer.get_backend('statevector_simulator')\n",
    "\n",
    "def Z_featuremap(x, qubits, repeats):\n",
    "    z_featuremap = QuantumCircuit(qubits)\n",
    "    z_featuremap.initialize([1,0], 0)\n",
    "    z_featuremap.initialize([1,0], 1)\n",
    "    for i in range(repeats):\n",
    "        z_featuremap.h(0)\n",
    "        z_featuremap.h(1)\n",
    "        z_featuremap.p(2*np.pi/2*x[0],0)\n",
    "        z_featuremap.p(2*np.pi/2*x[1],1)\n",
    "        z_featuremap.barrier()\n",
    "    z_featuremap_picture = z_featuremap.draw()\n",
    "    return z_featuremap, z_featuremap_picture \n",
    "\n",
    "def ZZ_featuremap(x, qubits, repeats):\n",
    "    zz_featuremap = QuantumCircuit(qubits)\n",
    "    zz_featuremap.initialize([1,0], 0)\n",
    "    zz_featuremap.initialize([1,0], 1)\n",
    "    for i in range(repeats):\n",
    "        zz_featuremap.h(0)\n",
    "        zz_featuremap.h(1)\n",
    "        zz_featuremap.p(2*np.pi/2*x[0],0)\n",
    "        zz_featuremap.p(2*np.pi/2*x[1],1)\n",
    "        zz_featuremap.cx(0,1)\n",
    "        zz_featuremap.p(2*(np.pi-np.pi/2*x[0])*(np.pi-np.pi/2*x[1]), 1)\n",
    "        zz_featuremap.cx(0,1)\n",
    "        zz_featuremap.barrier()\n",
    "    zz_featuremap_picture = zz_featuremap.draw()\n",
    "    return zz_featuremap, zz_featuremap_picture  \n",
    "\n",
    "def Custom1_featuremap(x, qubits, repeats):\n",
    "    custom1_featuremap = QuantumCircuit(qubits)\n",
    "    custom1_featuremap.initialize([1,0], 0)\n",
    "    custom1_featuremap.initialize([1,0], 1)\n",
    "    for _ in range(repeats): \n",
    "        custom1_featuremap.h(1)\n",
    "        custom1_featuremap.rx(np.pi/2*x[0], 0)\n",
    "        custom1_featuremap.ry(np.pi/2*x[1], 1)\n",
    "        for i in range(qubits):\n",
    "            for j in range(i+1, qubits):\n",
    "                custom1_featuremap.cx(i, j)\n",
    "                custom1_featuremap.p(np.sin(np.pi/2*x[i]) * np.cos(np.pi/2*x[j]), j)\n",
    "                custom1_featuremap.cx(i, j)\n",
    "        custom1_featuremap.barrier()\n",
    "    custom1_featuremap_picture = custom1_featuremap.draw()\n",
    "    return custom1_featuremap, custom1_featuremap_picture  \n",
    "\n",
    "def Custom2_featuremap(x, qubits, repeats):\n",
    "    custom2_featuremap = QuantumCircuit(qubits)\n",
    "    custom2_featuremap.initialize([1,0],0)\n",
    "    custom2_featuremap.initialize([1,0],1)\n",
    "    for _ in range(repeats):\n",
    "        custom2_featuremap.rx(np.arcsin(2/np.pi*x[0]), 0)\n",
    "        custom2_featuremap.rz(np.arccos(2/np.pi*2/np.pi*x[0]*x[0]), 0)\n",
    "        custom2_featuremap.rx(np.arcsin(2/np.pi*x[1]), 1)\n",
    "        custom2_featuremap.rz(np.arccos(2/np.pi*2/np.pi*x[1]*x[1]), 1)\n",
    "        custom2_featuremap.barrier()\n",
    "        custom2_featuremap.barrier()\n",
    "    custom2_featuremap_picture = custom2_featuremap.draw()\n",
    "    return custom2_featuremap, custom2_featuremap_picture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf, zf_draw = Z_featuremap(x, qubits, 1)\n",
    "zzf, zzf_draw = ZZ_featuremap(x, qubits, 1)\n",
    "c1, c1_draw = Custom1_featuremap(x, qubits, 1)\n",
    "c2, c2_draw = Custom2_featuremap(x, qubits, 1)\n",
    "\n",
    "kernel = lambda fmap, backend: QuantumKernel(feature_map = fmap, quantum_instance = backend)\n",
    "\n",
    "maps = [zf, zzf, c1, c2]\n",
    "def make_kernels(maps):\n",
    "    kernels = []\n",
    "    for map in maps:\n",
    "        kernels.append(kernel(map, backend))\n",
    "    return kernels\n",
    "Quantum_Kernels = make_kernels(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "\n",
    "set_train_qsvm, labels_train_qsvm = train_test_split(dataset[0], labels[0], train_size=50, random_state= 402)[\n",
    "    ::2\n",
    "]  \n",
    "\n",
    "labelss = labels[1][:3000]\n",
    "datasets = dataset[1][:3000]\n",
    "partitions = np.append(\n",
    "    -np.ones(labels_train_qsvm.shape[0], dtype=int),\n",
    "    np.zeros(labelss.shape[0], dtype=int),\n",
    ")\n",
    "\n",
    "validation_idx = PredefinedSplit(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"C\": [20, 50, 150, 500],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel = 'precomputed'), opt, refit=True, verbose=3, cv=validation_idx)\n",
    "set_train_val = np.concatenate((np.pi/2*set_train_qsvm, np.pi/2*datasets), axis=0)\n",
    "labels_train_val = np.concatenate((labels_train_qsvm, labelss), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n",
      "[CV 1/1] END ..............................C=20;, score=0.660 total time=   0.0s\n",
      "[CV 1/1] END ..............................C=50;, score=0.658 total time=   0.0s\n",
      "[CV 1/1] END .............................C=150;, score=0.621 total time=   0.0s\n",
      "[CV 1/1] END .............................C=500;, score=0.613 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=SVC(kernel='precomputed'),\n",
       "             param_grid={'C': [20, 50, 150, 500]}, verbose=3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(Quantum_Kernels[3].evaluate(x_vec = set_train_val), labels_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "gau = SVC(C = 1, gamma = 10).fit(set_train_qsvm, labels_train_qsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gau.score(datasets, labelss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_train_val.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0a4c11616797343aec84642c427ab734a4fa6446bc9cef6ab263c223e5620f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
